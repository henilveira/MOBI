{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq \n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra(grid, start, goal_row):\n",
    "    rows, cols = grid.shape\n",
    "    visitados = set()\n",
    "    stack = [start]\n",
    "\n",
    "    while stack:\n",
    "        x, y = stack.pop()\n",
    "        if (x, y) in visitados:\n",
    "            continue\n",
    "        visitados.add((x, y))\n",
    "\n",
    "        # chegou em qualquer célula da primeira linha\n",
    "        if x == goal_row:\n",
    "            return 1\n",
    "\n",
    "        # vizinhos (cima, baixo, esquerda, direita)\n",
    "        for dx, dy in [(1,0), (-1,0), (0,1), (0,-1)]:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < rows and 0 <= ny < cols and grid[nx, ny] == 0:\n",
    "                stack.append((nx, ny))\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_datasets(samples, size, prob):\n",
    "    X, Y = [], []\n",
    "    for _ in range(samples):\n",
    "        grid = np.random.choice([0,1], (size, size), p=[1-prob, prob])\n",
    "        start = (size - 1, size//2)\n",
    "        grid[start] = 0\n",
    "        labels = 2  # duas classes: possível (1) ou não (0)\n",
    "\n",
    "        X.append(grid)\n",
    "        Y.append(dijkstra(grid, start, 0))  # retorna 0 ou 1\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    one_hotted_Y = np.eye(labels)[Y] \n",
    "\n",
    "    # ⚡ Achata cada grid 2D em vetor 1D\n",
    "    X_flat = X.reshape(X.shape[0], -1)  # shape -> (samples, size*size)\n",
    "\n",
    "    return X, X_flat, Y, one_hotted_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testando\n",
    "X, Y, one_hot = generate_datasets(3, 3, 0.4)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Mapa:\")\n",
    "    print(X[i])\n",
    "    print(\"One Hot:\", one_hot[i])\n",
    "    print(\"Saida:\", Y[i])\n",
    "    print(\"-----\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parms(samples, size, prob):\n",
    "    X_map, X, Y, y_true = generate_datasets(samples=samples, size=size, prob=prob)\n",
    "\n",
    "    input_dim = X.shape[1]          # features\n",
    "    hidden_dim = size               # tamanho da camada oculta\n",
    "    output_dim = y_true.shape[1]    # número de classes (ex: 2)\n",
    "\n",
    "    W1 = np.random.rand(input_dim, hidden_dim)\n",
    "    b1 = np.zeros((1, hidden_dim))\n",
    "    W2 = np.random.rand(hidden_dim, output_dim)\n",
    "    b2 = np.zeros((1, output_dim))\n",
    "\n",
    "    return X_map, X, Y, y_true, W1, b1, W2, b2\n",
    "\n",
    "    \n",
    "def forward_prop(X, W1, b1, W2, b2):\n",
    "    Z1 = X.dot(W1) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = A1.dot(W2) + b2\n",
    "    y_pred = softmax(Z2)\n",
    "    return Z1, A1, Z2, y_pred \n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred + eps),   axis=1))\n",
    "    \n",
    "def backward_prop(Z1, A1, Z2, y_pred, W1, W2, X, y_true):\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # Saída\n",
    "    dZ2 = y_pred - y_true                # (N, output_dim)\n",
    "    dW2 = np.dot(A1.T, dZ2) / N\n",
    "    db2 = np.mean(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    # Oculta\n",
    "    d_hidden = np.dot(dZ2, W2.T) * ReLU_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, d_hidden) / N\n",
    "    db1 = np.mean(d_hidden, axis=0, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "\n",
    "    # Saída\n",
    "    dZ2 = y_pred - y_true\n",
    "    dW2 = np.dot(A1.T, dZ2) / dims\n",
    "    db2 = np.mean(dZ2, axis=0)\n",
    "\n",
    "    # Camada oculta\n",
    "    d_hidden = np.dot(dZ2, W2.T) * ReLU_derivative(Z1)\n",
    "    dW1 = np.dot(X.T, d_hidden) / dims\n",
    "    db1 = np.mean(d_hidden, axis=0)  \n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1   \n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2\n",
    "    \n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "    \n",
    "def ReLU(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def ReLU_derivative(z):\n",
    "    return (z > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(y_pred):\n",
    "    return np.argmax(y_pred, 0)\n",
    "\n",
    "def get_predictions(y_pred):\n",
    "    return np.argmax(y_pred, axis=1) \n",
    "\n",
    "def test_model(X_test, X_map, Y_test, W1, b1, W2, b2, samples):\n",
    "    # Forward pass\n",
    "    Z1 = np.dot(X_test, W1) + b1\n",
    "    A1 = np.maximum(0, Z1)               # ReLU\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    expZ = np.exp(Z2 - np.max(Z2, axis=1, keepdims=True))\n",
    "    y_pred = expZ / np.sum(expZ, axis=1, keepdims=True)  # softmax\n",
    "\n",
    "    # Classes previstas\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Acurácia\n",
    "    accuracy = np.mean(predictions == Y_test)\n",
    "\n",
    "    # Mostrar alguns exemplos\n",
    "    print(\"Exemplos de teste:\")\n",
    "    for i in range(samples):\n",
    "        if i % 25 == 0:\n",
    "\n",
    "            print(f\"Exemplo {i}:\")\n",
    "            print(f\"  Mapa: \\n{X_map[i]}\")\n",
    "            print(f\"  Saída real: {Y_test[i]}\")\n",
    "            print(f\"  Saída prevista: {predictions[i]}\")\n",
    "            print(f\"  Probabilidades: {y_pred[i]}\")\n",
    "            print(\"-\"*30)\n",
    "\n",
    "    print(f\"\\nAcurácia total: {accuracy*100:.2f}%\")\n",
    "\n",
    "    return y_pred, predictions, accuracy\n",
    "\n",
    "\n",
    "def gradient_descent(samples, size, prob, alpha):\n",
    "    X_map, X, Y, y_true, W1, b1, W2, b2 = init_parms(samples, size, prob)\n",
    "    for i in range(samples):\n",
    "        Z1, A1, Z2, y_pred = forward_prop(X, W1, b1, W2, b2)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, y_pred, W1, W2, X, y_true)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        print(f\"Iteration: {i}\")\n",
    "        y_pred_test, predictions, accuracy = test_model(X, X_map, Y, W1, b1, W2, b2, samples)\n",
    "        print(f\"Acurácia no dataset de treino: {accuracy*100:.2f}%\\n\")\n",
    "    return W1, b1, W2, b2, X, Y, X_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2, X, Y, X_map = gradient_descent(samples=2000, size=4, prob=0.35, alpha=0.12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
